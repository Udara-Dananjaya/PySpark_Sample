{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name :- Udara Dananjaya /\n",
        "Student ID :- BSIT 211004 /\n",
        "NIC No. :- 200028900467 /\n",
        "Subject :- Big Data Analytics (BSIT 31023)\n",
        "\n",
        "\n",
        "\n",
        "> **Assignment**\n",
        "\n",
        "For my assignment I used spark to do various operations with big data. Pyspark is the python API of spark. There are two types of operations, transformations and actions. Transformations are the operations that applied to dataset to create new dataset. Actions are the operations which instructs Spark to perform computaion and send the output back to driver.\n",
        "\n",
        "To perform operations we have two options, RDD and Dataframe. RDD (Resilient Distributed Dataset) is the collection of different types of objects. Also it is a fundamental structure of data and fixed collection of data that calculates on a cluster's different nodes. Dataframe is a distributed collection of data. It is arranged into named columns.\n",
        "\n",
        "In here, I used the dataframe concept to do this assignment.\n",
        "\n",
        "First I need to setup our environment. I want to install pyspark (Python package), PyDrive (Python library used for working with Google Drive and interacting with files and folders in Google Drive through Python code) and JDK (Java Development Kit).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n0k5F-g-a2mA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YQv1BDJYX4h",
        "outputId": "eeda45bc-6b1e-4231-c63d-0943dbf427bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark --quiet\n",
        "!pip install -U -q PyDrive --quiet\n",
        "!apt install openjdk-8-jdk-headless &> /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I have to import Operating System to my environmet, so that I import open jdk."
      ],
      "metadata": {
        "id": "Lusbx2k2a0zo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "U_ZPVKa9Zrag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I import **SparkSession** class from **pyspark.sql** module. Afterthat I creat a object called \"spark\" in SparkSession class. And it includes\n",
        "**SparkSession.builder** (creates a builder object that allows you to configure the SparkSession), **.appName** (sets the name of your Spark application to \"BigDataAssignment.\"), **.config** (configures Spark to use port 4050 for its web user interface (UI). The Spark UI provides information about the status and progress of your Spark application), and **.getOrCreate** ( method either retrieves an existing SparkSession or creates a new one if it doesn't exist)."
      ],
      "metadata": {
        "id": "NlljnuT4jhv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"BigDataAssignment\") \\\n",
        "        .config(\"spark.ui.port\", \"4050\") \\\n",
        "        .getOrCreate()\n"
      ],
      "metadata": {
        "id": "opqtwrOyZ4gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If I want to details about my spark application, I can use following command."
      ],
      "metadata": {
        "id": "PZhKY-K2lfpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "BrhuHyxWbP2Q",
        "outputId": "62cd1702-5c3e-4b2f-b7fe-e421e051ab22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd22411db70>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://89b180502e67:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>BigDataAssignment</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In pyspark we have two options to read a big data file. First method is upload a file to drive and read it. Second one is give URL from (!wget) command. In here, I used first option that upload a file from local device to drive and read.\n",
        "\n",
        "To perform that task I need to import \"files\" class from \"google.colab\" library. I used \"upload()\" function to get the file from local device and \"uploaded\" containing uploaded files.\n",
        "\n",
        "I downloaded a csv file named as \"films.csv\" that contains the details about several films. I included that file to my folder."
      ],
      "metadata": {
        "id": "mgkVjKpal08t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "v_Kwc9OUbTwe",
        "outputId": "70f19b5b-4e55-4c23-8301-ffbbb6b7be7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0fc032af-b42d-421d-a4c7-10992386aa0a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0fc032af-b42d-421d-a4c7-10992386aa0a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving films.csv to films.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPRVrYFYcO7o",
        "outputId": "2b57425d-cc75-4d61-fe24-baf9b11bfe02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'film (1).csv'\t film.csv   films.csv   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create dataframe manually by using \"createDataFrame()\" function. But in this case I want to create dataframe by using my \"films.csv\" file. So that I used \"spark.read.csv()\" command."
      ],
      "metadata": {
        "id": "IXhcXPUwn__l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also here I gave \"df.columns\" command that retrieve only the column names."
      ],
      "metadata": {
        "id": "jkCJbdHYpj1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Qi3SuqiNpi1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('films.csv', header = True, sep = \";\")\n",
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k64opTyXcaWg",
        "outputId": "2e0ad482-9092-45cb-a732-535ce3d70576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Year',\n",
              " 'Length',\n",
              " 'Title',\n",
              " 'Subject',\n",
              " 'Actor',\n",
              " 'Actress',\n",
              " 'Director',\n",
              " 'Popularity',\n",
              " 'Awards',\n",
              " '*Image,,,,,']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"df.dtypes\" command retrieve the dataframe schema."
      ],
      "metadata": {
        "id": "0B99jWlIqWVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxD6fVTcdVtp",
        "outputId": "476bbf5c-9b34-4f44-8919-e6e2b01db5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Year', 'int'),\n",
              " ('Length', 'int'),\n",
              " ('Title', 'string'),\n",
              " ('Subject', 'string'),\n",
              " ('Actor', 'string'),\n",
              " ('Actress', 'string'),\n",
              " ('Director', 'string'),\n",
              " ('Popularity', 'int'),\n",
              " ('Awards', 'string'),\n",
              " ('*Image,,,,,', 'string')]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or else I can use this \"df.printSchema()\" function to view schema of the dataframe."
      ],
      "metadata": {
        "id": "6hI4Gq7buPXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7bu1fEkhhZo",
        "outputId": "83fc8a15-9710-4a82-854e-3fed85a632ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Length: integer (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Actor: string (nullable = true)\n",
            " |-- Actress: string (nullable = true)\n",
            " |-- Director: string (nullable = true)\n",
            " |-- Popularity: integer (nullable = true)\n",
            " |-- Awards: string (nullable = true)\n",
            " |-- *Image,,,,,: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inferring Schema Implicitly**\n",
        "\n",
        "'films.csv': This is the path to the CSV file you want to read. It should exist in the current working directory or be specified with the full path.\n",
        "\n",
        "header = True: This option specifies that the first row of the CSV file contains the column names (header).\n",
        "\n",
        "sep = \";\": This option specifies the delimiter used in the CSV file. In this case, it's a semicolon (;).\n",
        "\n",
        "inferSchema = True: This option tells PySpark to infer the data types of the columns automatically."
      ],
      "metadata": {
        "id": "WRfmqbiLufiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('films.csv', header = True, sep = \";\", inferSchema = True)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "BKWMwvU6rXhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Viewing the Dataframe**\n",
        "\n",
        "There are several methods to get the values from dataframe, but here I used \"df.show()\" function. Other options are,\n",
        "\n",
        "df.take() - used to retrieve the first N rows from a DataFrame\n",
        "\n",
        "df.collect() - used to retrieve all the rows from a DataFrame and return them as a local Python list\n",
        "\n",
        "df.limit() - used to restrict the number of rows that are returned from a DataFrame\n",
        "\n",
        "And, truncate: This argument is a boolean that controls whether long strings in the DataFrame should be truncated to fit within the column width. In your code, you've set it to False, which means long strings will not be truncated."
      ],
      "metadata": {
        "id": "Lwfe9CtzrXIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(20, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMQAMLOgqxbb",
        "outputId": "7d61b9cb-55b6-4f42-b852-9e97ca6294e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+--------------------------------------+-------+-----------------------+-------------------+------------------------+----------+------+---------------------+\n",
            "|Year|Length|Title                                 |Subject|Actor                  |Actress            |Director                |Popularity|Awards|*Image,,,,,          |\n",
            "+----+------+--------------------------------------+-------+-----------------------+-------------------+------------------------+----------+------+---------------------+\n",
            "|1990|111   |Tie Me Up! Tie Me Down!               |Comedy |Banderas, Antonio      |Abril, Victoria    |Almod�var, Pedro        |68        |No    |NicholasCage.png,,   |\n",
            "|1991|113   |High Heels                            |Comedy |Bos�, Miguel           |Abril, Victoria    |Almod�var, Pedro        |68        |No    |NicholasCage.png,,   |\n",
            "|1983|104   |Dead Zone, The                        |Horror |Walken, Christopher    |Adams, Brooke      |Cronenberg, David       |79        |No    |NicholasCage.png,    |\n",
            "|1979|122   |Cuba                                  |Action |Connery, Sean          |Adams, Brooke      |Lester, Richard         |6         |No    |seanConnery.png,,    |\n",
            "|1978|94    |Days of Heaven                        |Drama  |Gere, Richard          |Adams, Brooke      |Malick, Terrence        |14        |No    |NicholasCage.png,,   |\n",
            "|1983|140   |Octopussy                             |Action |Moore, Roger           |Adams, Maud        |Glen, John              |68        |No    |NicholasCage.png,,   |\n",
            "|1984|101   |Target Eagle                          |Action |Connors, Chuck         |Adams, Maud        |Loma, Jos� Antonio de la|14        |No    |NicholasCage.png,,   |\n",
            "|1989|99    |American Angels: Baptism of Blood, The|Drama  |Bergen, Robert D.      |Adams, Trudy       |Sebastian, Beverly      |28        |No    |NicholasCage.png,    |\n",
            "|1985|104   |Subway                                |Drama  |Lambert, Christopher   |Adjani, Isabelle   |Besson, Luc             |6         |No    |NicholasCage.png,,   |\n",
            "|1990|149   |Camille Claudel                       |Drama  |Depardieu, G�rard      |Adjani, Isabelle   |Nuytten, Bruno          |32        |No    |NicholasCage.png,,   |\n",
            "|1982|188   |Fanny and Alexander                   |Drama  |Ahlstedt, B�rje        |Adolphson, Kristina|Bergman, Ingmar         |81        |Yes   |Bergman.png,,        |\n",
            "|1982|117   |Tragedy of a Ridiculous Man           |Drama  |Tognazzi, Ugo          |Aimee, Anouk       |Bertolucci, Bernardo    |17        |No    |NicholasCage.png,,   |\n",
            "|1966|103   |A Man & a Woman                       |Drama  |Trintignant, Jean-Louis|Aimee, Anouk       |Lelouch, Claude         |46        |Yes   |NicholasCage.png,,   |\n",
            "|1986|112   |A Man & a Woman: Twenty Years Later   |Drama  |Trintignant, Jean-Louis|Aimee, Anouk       |Lelouch, Claude         |49        |No    |NicholasCage.png,,   |\n",
            "|1966|103   |Un Hombre y una Mujer                 |Drama  |Trintignant, Jean-Louis|Aimee, Anouk       |Lelouch, Claude         |6         |Yes   |NicholasCage.png,,   |\n",
            "|1985|112   |Official Story, The                   |Drama  |Alterio, Hector        |Aleandro, Norma    |Puenzo, Luiz            |39        |Yes   |NicholasCage.png,    |\n",
            "|1976|150   |Lindbergh Kidnapping Case, The        |Drama  |Hopkins, Anthony       |Alexander, Denise  |Kulik, Buzz             |51        |No    |AnthonyHopkins.png,  |\n",
            "|1929|84    |Blackmail                             |Mystery|Longden, John          |Algood, Sara       |Hitchcock, Alfred       |2         |No    |alfredHitchcock.png,,|\n",
            "|1963|109   |Donovan's Reef                        |Comedy |Wayne, John            |Allen, Elizabeth   |Ford, John              |62        |No    |johnWayne.png,,      |\n",
            "|1988|110   |Tucker: The Man & His Dream           |Drama  |Bridges, Jeff          |Allen, Joan        |Coppola, Francis Ford   |68        |No    |NicholasCage.png,,   |\n",
            "+----+------+--------------------------------------+-------+-----------------------+-------------------+------------------------+----------+------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Schema Explicitly**\n",
        "\n",
        "If we want to define the schema of the dataframe, we can use this method.\n",
        "\n",
        "First, I import necessary data types from \"pyspark.sql.types\"\n",
        "\n",
        "Second, I create a list of column names and their corresponding data types as tuples\n",
        "\n",
        "In my example, I changed 'Length' datatype as a 'DoubleType'"
      ],
      "metadata": {
        "id": "TNmTfzYexjsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "labels = [\n",
        "    ('Year', IntegerType()),\n",
        "    ('Length', DoubleType()),\n",
        "    ('Title', StringType()),\n",
        "    ('Subject', StringType()),\n",
        "    ('Actor', StringType()),\n",
        "    ('Actress', StringType()),\n",
        "    ('Director', StringType()),\n",
        "    ('Popularity', IntegerType()),\n",
        "    ('Awards', StringType()),\n",
        "    ('Image', StringType())\n",
        "]"
      ],
      "metadata": {
        "id": "55uwGTJCpPJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afterthat, I define the schema for the dataframe according to the list that i have created."
      ],
      "metadata": {
        "id": "N8Xy0cSUyqPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField (x[0], x[1], True) for x in labels])\n",
        "schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD9TK-IOrj7-",
        "outputId": "beb05ac3-2aea-4e8b-afb3-876e344888f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StructType([StructField('Year', IntegerType(), True), StructField('Length', IntegerType(), True), StructField('Title', StringType(), True), StructField('Subject', StringType(), True), StructField('Actor', StringType(), True), StructField('Actress', StringType(), True), StructField('Director', StringType(), True), StructField('Popularity', DoubleType(), True), StructField('Awards', StringType(), True), StructField('Image', StringType(), True)])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finnally, I created the dataframe with my schema.\n",
        "\n",
        "schema=schema: Specifies the schema that I defined earlier using the schema variable. This schema defines the structure and data types of the dataframe."
      ],
      "metadata": {
        "id": "9vkMQP0Kzi5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('films.csv', header = True, sep = \";\", schema = schema)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RPZGWLossNL",
        "outputId": "ba85aaf5-0b54-456b-d981-3ec800ebb23c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Length: integer (nullable = true)\n",
            " |-- Title: string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Actor: string (nullable = true)\n",
            " |-- Actress: string (nullable = true)\n",
            " |-- Director: string (nullable = true)\n",
            " |-- Popularity: double (nullable = true)\n",
            " |-- Awards: string (nullable = true)\n",
            " |-- Image: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show (20, truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPYAEh5mtKQD",
        "outputId": "e3dcc02f-42bb-4e9f-f3fb-42eefa9c4800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+--------------------------------------+-------+-----------------------+-------------------+------------------------+----------+------+---------------------+\n",
            "|Year|Length|Title                                 |Subject|Actor                  |Actress            |Director                |Popularity|Awards|Image                |\n",
            "+----+------+--------------------------------------+-------+-----------------------+-------------------+------------------------+----------+------+---------------------+\n",
            "|1990|111   |Tie Me Up! Tie Me Down!               |Comedy |Banderas, Antonio      |Abril, Victoria    |Almod�var, Pedro        |68.0      |No    |NicholasCage.png,,   |\n",
            "|1991|113   |High Heels                            |Comedy |Bos�, Miguel           |Abril, Victoria    |Almod�var, Pedro        |68.0      |No    |NicholasCage.png,,   |\n",
            "|1983|104   |Dead Zone, The                        |Horror |Walken, Christopher    |Adams, Brooke      |Cronenberg, David       |79.0      |No    |NicholasCage.png,    |\n",
            "|1979|122   |Cuba                                  |Action |Connery, Sean          |Adams, Brooke      |Lester, Richard         |6.0       |No    |seanConnery.png,,    |\n",
            "|1978|94    |Days of Heaven                        |Drama  |Gere, Richard          |Adams, Brooke      |Malick, Terrence        |14.0      |No    |NicholasCage.png,,   |\n",
            "|1983|140   |Octopussy                             |Action |Moore, Roger           |Adams, Maud        |Glen, John              |68.0      |No    |NicholasCage.png,,   |\n",
            "|1984|101   |Target Eagle                          |Action |Connors, Chuck         |Adams, Maud        |Loma, Jos� Antonio de la|14.0      |No    |NicholasCage.png,,   |\n",
            "|1989|99    |American Angels: Baptism of Blood, The|Drama  |Bergen, Robert D.      |Adams, Trudy       |Sebastian, Beverly      |28.0      |No    |NicholasCage.png,    |\n",
            "|1985|104   |Subway                                |Drama  |Lambert, Christopher   |Adjani, Isabelle   |Besson, Luc             |6.0       |No    |NicholasCage.png,,   |\n",
            "|1990|149   |Camille Claudel                       |Drama  |Depardieu, G�rard      |Adjani, Isabelle   |Nuytten, Bruno          |32.0      |No    |NicholasCage.png,,   |\n",
            "|1982|188   |Fanny and Alexander                   |Drama  |Ahlstedt, B�rje        |Adolphson, Kristina|Bergman, Ingmar         |81.0      |Yes   |Bergman.png,,        |\n",
            "|1982|117   |Tragedy of a Ridiculous Man           |Drama  |Tognazzi, Ugo          |Aimee, Anouk       |Bertolucci, Bernardo    |17.0      |No    |NicholasCage.png,,   |\n",
            "|1966|103   |A Man & a Woman                       |Drama  |Trintignant, Jean-Louis|Aimee, Anouk       |Lelouch, Claude         |46.0      |Yes   |NicholasCage.png,,   |\n",
            "|1986|112   |A Man & a Woman: Twenty Years Later   |Drama  |Trintignant, Jean-Louis|Aimee, Anouk       |Lelouch, Claude         |49.0      |No    |NicholasCage.png,,   |\n",
            "|1966|103   |Un Hombre y una Mujer                 |Drama  |Trintignant, Jean-Louis|Aimee, Anouk       |Lelouch, Claude         |6.0       |Yes   |NicholasCage.png,,   |\n",
            "|1985|112   |Official Story, The                   |Drama  |Alterio, Hector        |Aleandro, Norma    |Puenzo, Luiz            |39.0      |Yes   |NicholasCage.png,    |\n",
            "|1976|150   |Lindbergh Kidnapping Case, The        |Drama  |Hopkins, Anthony       |Alexander, Denise  |Kulik, Buzz             |51.0      |No    |AnthonyHopkins.png,  |\n",
            "|1929|84    |Blackmail                             |Mystery|Longden, John          |Algood, Sara       |Hitchcock, Alfred       |2.0       |No    |alfredHitchcock.png,,|\n",
            "|1963|109   |Donovan's Reef                        |Comedy |Wayne, John            |Allen, Elizabeth   |Ford, John              |62.0      |No    |johnWayne.png,,      |\n",
            "|1988|110   |Tucker: The Man & His Dream           |Drama  |Bridges, Jeff          |Allen, Joan        |Coppola, Francis Ford   |68.0      |No    |NicholasCage.png,,   |\n",
            "+----+------+--------------------------------------+-------+-----------------------+-------------------+------------------------+----------+------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In following code, I defined a variable as \"data_count\" and get the row count of the dataframe by using \"df.count()\" function."
      ],
      "metadata": {
        "id": "1a7Ki97g1ROj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_count = df.count()\n",
        "print (\"Total count of data : \" + str(data_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeKelTxgwENO",
        "outputId": "c4d9aabe-76a4-4534-fb92-4c21f304848c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total count of data : 1659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataFrame Operations on Columns**\n",
        "\n",
        "There can do several operations based on the columns. First I do the **select** operation. In that case there are two types of select operations, Single column selection and Multiple column selection.\n",
        "\n",
        "Case 1: I want to retrieve the all the Title of films using dot notation."
      ],
      "metadata": {
        "id": "fe7ikrApKl4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.Title).show(truncate = False)"
      ],
      "metadata": {
        "id": "9P0dKCDALyYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also I can get these values from another method."
      ],
      "metadata": {
        "id": "OHN_KqISMxUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df['Title']).show(truncate = False)"
      ],
      "metadata": {
        "id": "CeJR0PsQM333"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And finally I can do same operation by using **pyspark.sql.functions** library."
      ],
      "metadata": {
        "id": "sBUp-ni8NGa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.select(col('Title')).show(truncate = False)"
      ],
      "metadata": {
        "id": "Nh8fTP7VNcAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 2 : I need the year and the title of the all films."
      ],
      "metadata": {
        "id": "QTLjLNJEOKLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.select(col('Title'),col('Year')).show(truncate = False)"
      ],
      "metadata": {
        "id": "hO4xNoowOXQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 3: Retrieve title, length and type of each film."
      ],
      "metadata": {
        "id": "SuPVnu2BO5gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.select(col('Title'),col('Length'),col('Subject')).show(truncate = False)"
      ],
      "metadata": {
        "id": "JYzmu8HvPFEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 4: Give me the director, actor and actress name of an each film."
      ],
      "metadata": {
        "id": "d1A9oYoyPflJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.select(col('Title'),col('Director'),col('Actor'),col('Actress')).show(truncate = False)"
      ],
      "metadata": {
        "id": "6qBFIRbYPwxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 5: Details about the popularity and awards of each film"
      ],
      "metadata": {
        "id": "RwlsYaWnQTz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "df.select(col('Title'),col('Popularity'),col('Awards')).show(truncate = False)"
      ],
      "metadata": {
        "id": "yuoTi9XaQmLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I move to the next operation. That is **adding** a new columns to the dataframe. So there are three options, Add single column, Add multiple columns, And deriving a new column from an exisitng one.\n",
        "\n",
        "Case 1: I want to add a new column to this dataframe called as \"Country\" and it contains \"US\". That means these all movies are made in US."
      ],
      "metadata": {
        "id": "vLEMnN9TWJ8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit\n",
        "df = df.withColumn('Country',lit(\"US\"))\n",
        "df.show(truncate = False)"
      ],
      "metadata": {
        "id": "BPNwSyYjX2tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**lit** means literal. It populates the row with the literal value given.\n",
        "\n",
        "Case 2: I want to add a new column as \"Title_year\" which has value of title and year appended together with a space in between. Also add another column to store static value called \"Released\"."
      ],
      "metadata": {
        "id": "fptiSXU8YVeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import concat\n",
        "df = df.withColumn('Title_year', concat(col(\"Title\"), lit(\" \"), col(\"Year\"))) \\\n",
        "        .withColumn('Status', lit(\"Released\"))\n",
        "df.show(truncate = False)"
      ],
      "metadata": {
        "id": "T0D2TiOTc8dZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another operation is **renaming** the column.\n",
        "\n",
        "Case 1 : Rename the \"Subject\" column as \"Category\".\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P5JEbZ-veo64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed('Subject','Category')\n",
        "df.show(truncate = False)"
      ],
      "metadata": {
        "id": "CsmOQJ8kfAQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can **remove** a single column and also multiple columns.\n",
        "\n",
        "Case 1: Remove \"Status\" column"
      ],
      "metadata": {
        "id": "kVLxP1g2fm7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Status')\n",
        "df.show(10, truncate = False)"
      ],
      "metadata": {
        "id": "4xIxW_0ufvS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 2 : Remove \"Titel_year\" column and \"Country\" column at the same time."
      ],
      "metadata": {
        "id": "TRQeIxksgGli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Title_year') \\\n",
        "        .drop('Country')\n",
        "df.show(5, truncate = False)"
      ],
      "metadata": {
        "id": "NeuVUr96gZuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another Important operation is **Group By Column**.\n",
        "\n",
        "Case 1 : Give count of different categories of filems.\n",
        "\n"
      ],
      "metadata": {
        "id": "xt9bDI-4kYOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('Category').count.show(5, truncate = False)"
      ],
      "metadata": {
        "id": "BBPWQctimkH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 2: Count of awarded and non-awarded."
      ],
      "metadata": {
        "id": "9wz7sUH8w3yO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('Awards').count.show(5, truncate = False)"
      ],
      "metadata": {
        "id": "5UUJURjUw1KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 3: Count of films that each actress acts."
      ],
      "metadata": {
        "id": "UsRFi9JYxU42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('Actress').count.show(truncate = False)"
      ],
      "metadata": {
        "id": "iFTaX_mpyCkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 4: Group by \"Actor\" and \"Actress\"."
      ],
      "metadata": {
        "id": "DVma7Wz0XRRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy('Actor','Actress').count.show(truncate = False)"
      ],
      "metadata": {
        "id": "Qn_LMvMKXaOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataframe Operations on Rows**\n",
        "\n",
        "The first operation is **filtering** rows.\n",
        "\n",
        "Case 1: Get count of \"Action\" films and retrieve those films."
      ],
      "metadata": {
        "id": "zYPVeLLwDKgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_films = df.filter(col('Category') == \"Action\").count()\n",
        "print(\"Count of action films: \" + str(action_films))\n",
        "df.filter(col('Category') == \"Action\").show(truncate = False)"
      ],
      "metadata": {
        "id": "VE7DmKMXD8xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 2: Get the details about the awarded films."
      ],
      "metadata": {
        "id": "ACFqt4DYHILT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter(col('Awards') == \"Yes\").show(truncate = False)"
      ],
      "metadata": {
        "id": "8CEurxI3HRy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 3: Give the film list that \"Trintignant, Jean-Louis\" is the actor and \"Lelouch, Claude\" is the director."
      ],
      "metadata": {
        "id": "MAik22pNHiTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_count = df.filter(col('Actor') == \"Trintignant, Jean-Louis\" & col('Director') == \"Lelouch, Claude\").count()\n",
        "print(\"Count of films: \" + str(get_count))\n",
        "df.filter(col('Actor') == \"Trintignant, Jean-Louis\" & col('Director') == \"Lelouch, Claude\").show(truncate = False)"
      ],
      "metadata": {
        "id": "DXZXzy9xJhJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 4: How many films directed by Puenzo, Luiz have won awards and what are they?"
      ],
      "metadata": {
        "id": "qf8lKNtmcq1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "award_count = df.filter(col('Director') == \"Puenzo, Luiz\" & col('Awards') == \"Yes\").count()\n",
        "print(\"Count of Awarded films directed by Puenzo, Luiz : \" + str(award_count))\n",
        "df.filter(col('Director') == \"Puenzo, Luiz\" & col('Awards') == \"Yes\").show(truncate = False)"
      ],
      "metadata": {
        "id": "DoRXaS7Wfj24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get Distinct Rows** operation is used to get unique values from dataframe.\n",
        "\n",
        "Case 1: Get all the actors."
      ],
      "metadata": {
        "id": "z2kicUF8gOz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actor_count = df.select('Actor').distinct().count()\n",
        "print(\"There are  \" + str(actor_count) + \" actors in this dataframe.\")\n",
        "df.select('Actor').distinct().show(truncate = False)"
      ],
      "metadata": {
        "id": "ZJ369s_-g-Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 2: Who are the main characters who act together in the movies?"
      ],
      "metadata": {
        "id": "O2f3bD4Qg9Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_count = df.select('Actor','Actress').distinct().count()\n",
        "print(\"There are  \" + str(main_count) + \" data in this dataframe.\")\n",
        "df.select('Actor','Actress').distinct().show(truncate = False)"
      ],
      "metadata": {
        "id": "7WJcFIyPg2Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next operation is **Sorting Rows**.\n",
        "\n",
        "Case 1: List tha films by year in ascending order."
      ],
      "metadata": {
        "id": "AeFPY_2Us_vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy('Year').show(truncate = False)"
      ],
      "metadata": {
        "id": "qCZj4RrKtXfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 2: List the films by highest length to lowest length."
      ],
      "metadata": {
        "id": "mt6TOYGhtsZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy('Length', ascending=False).show(truncate = False)"
      ],
      "metadata": {
        "id": "n9cd1l9Rt5m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 3: List the films by highest popularity to lowest."
      ],
      "metadata": {
        "id": "clx4vWqxuHhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.orderBy('Popularity', ascending=False).show(truncate = False)"
      ],
      "metadata": {
        "id": "9XxFNdHOuZwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Case 4: Give the count of categories in ascending order"
      ],
      "metadata": {
        "id": "TbfUg3prudBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Categories\").count().orderBy('count').show(truncate = False)"
      ],
      "metadata": {
        "id": "RIS_eb8Rucvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "case 5: How many films get awarded?"
      ],
      "metadata": {
        "id": "jB5N3pO8vQfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Awards\").count().orderBy('count').show(truncate = False, ascending = False)"
      ],
      "metadata": {
        "id": "gn5T8ytsvZoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Union Dataframes**\n",
        "\n",
        "Case 1: Get the count of Action films and Mystery films with awards, then get tha count of all those two types."
      ],
      "metadata": {
        "id": "OG9iOU-KwOA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "action_films = df.filter((col('Category')=='Action') & (col('Awards')==\"Yes\"))\n",
        "mystery_films = df.filter((col('Category')=='Mystery') & (col('Awards')==\"Yes\"))\n",
        "print(\"Action Films: \"+str(action_films.count()))\n",
        "print(\"Mystery Films: \"+str(mystery_films.count()))\n",
        "print(\"AFTER UNION: \"+str(action_films.union(mystery_films).count()))"
      ],
      "metadata": {
        "id": "2MwNIrMxwlIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numeric functions**\n",
        "\n",
        "Case 1: Show the oldest film and newest film year\n",
        "\n",
        "Case 2: Get the highest length and lowest length\n",
        "\n",
        "Case 3: Highest popularity and lowest popularity"
      ],
      "metadata": {
        "id": "T4yaSpscxois"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "df.select(min(col('Year')), max(col('Year'))).show()"
      ],
      "metadata": {
        "id": "JPqGVpxCyLV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(max(col('Length')), min(col('Length'))).show()"
      ],
      "metadata": {
        "id": "WIX91dLFyafE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(max(col('Popularity')), min(col('Popularity'))).show()"
      ],
      "metadata": {
        "id": "KKg5l_9Xylqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}