{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHHonKk4z865",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c425d3-52ac-4468-889b-3224d8e07593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark --quiet\n",
        "!pip install -U -q PyDrive --quiet\n",
        "!apt install openjdk-8-jdk-headless &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "id": "YRSt_YCT0FEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"civComplaints\") \\\n",
        "    .config(\"spark.ui.port\", \"4050\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "fEp-58PL0Htk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "id": "Tlejyvpq362R",
        "outputId": "9c175b66-952c-4691-844a-4d005086a1b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f6ee97cbd60>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://65a71702e259:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>civComplaints</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --continue https://raw.githubusercontent.com/GarvitArya/pyspark-demo/main/sample_books.json -O /tmp/sample_books.json"
      ],
      "metadata": {
        "id": "d91wuuQp0OWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ccb38e-7ed9-4024-dc01-68115e0cd258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-13 16:16:51--  https://raw.githubusercontent.com/GarvitArya/pyspark-demo/main/sample_books.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1565 (1.5K) [text/plain]\n",
            "Saving to: ‘/tmp/sample_books.json’\n",
            "\n",
            "\r/tmp/sample_books.j   0%[                    ]       0  --.-KB/s               \r/tmp/sample_books.j 100%[===================>]   1.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-13 16:16:51 (16.6 MB/s) - ‘/tmp/sample_books.json’ saved [1565/1565]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json(\"/tmp/sample_books.json\")"
      ],
      "metadata": {
        "id": "OctfM9fk04ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd1Itqo-1HSg",
        "outputId": "29d9afc3-fd63-4cce-cafc-bbea4da7077c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- author: string (nullable = true)\n",
            " |-- edition: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year_written: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(4,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Z466RO1RAQ",
        "outputId": "413820d1-cdb7-444d-8465-dbaa22c6c392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+-----+----------------+------------+\n",
            "|author         |edition       |price|title           |year_written|\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "|Austen, Jane   |Penguin       |18.2 |Northanger Abbey|1814        |\n",
            "|Tolstoy, Leo   |Penguin       |12.7 |War and Peace   |1865        |\n",
            "|Tolstoy, Leo   |Penguin       |13.5 |Anna Karenina   |1875        |\n",
            "|Woolf, Virginia|Harcourt Brace|25.0 |Mrs. Dalloway   |1925        |\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBsa3Ss81X3f",
        "outputId": "b212909c-8d5d-4495-d15c-a8fa37f477da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OU8oHWbN1-yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('title', 'price', 'year_written').show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsroZdpO1dnl",
        "outputId": "dd681739-b947-424b-d5ae-5991719afd93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+------------+\n",
            "|           title|price|year_written|\n",
            "+----------------+-----+------------+\n",
            "|Northanger Abbey| 18.2|        1814|\n",
            "|   War and Peace| 12.7|        1865|\n",
            "|   Anna Karenina| 13.5|        1875|\n",
            "|   Mrs. Dalloway| 25.0|        1925|\n",
            "|       The Hours|12.35|        1999|\n",
            "+----------------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get books that are written after 1950 & cost greater than $10"
      ],
      "metadata": {
        "id": "nCWv1w942D84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df.filter(\"year_written > 1950 AND price > 10 AND title IS NOT NULL\")\n",
        "\n",
        "df_filtered.select(\"title\", \"price\", \"year_written\").show(50, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUUBJ1Ks1oSj",
        "outputId": "5cc23877-a9c5-453a-f3b6-517db77911ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+-----+------------+\n",
            "|title                        |price|year_written|\n",
            "+-----------------------------+-----+------------+\n",
            "|The Hours                    |12.35|1999        |\n",
            "|Harry Potter                 |19.95|2000        |\n",
            "|One Hundred Years of Solitude|14.0 |1967        |\n",
            "+-----------------------------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get books that have Harry Porter in their title"
      ],
      "metadata": {
        "id": "krzZqHNa2K8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.select(\"title\", \"year_written\").filter(\"title LIKE '%Harry Potter%'\").distinct().show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsRwXvjV2H2r",
        "outputId": "7bf0dc68-de16-4a24-ea5a-cb1e7ce34825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+\n",
            "|title       |year_written|\n",
            "+------------+------------+\n",
            "|Harry Potter|2000        |\n",
            "+------------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pyspark SQL functions:"
      ],
      "metadata": {
        "id": "txiBnaEv2bBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "# Find the costliest book\n",
        "maxValue = df_filtered.agg(max(\"price\")).collect()[0][0]\n",
        "print(\"maxValue: \",maxValue)\n",
        "df_filtered.select(\"title\",\"price\").filter(df.price == maxValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwC7pyNG2cFf",
        "outputId": "239c33a0-8441-423f-93c9-3a8456a5d591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxValue:  19.95\n",
            "+------------+-----+\n",
            "|title       |price|\n",
            "+------------+-----+\n",
            "|Harry Potter|19.95|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip &> /dev/null\n",
        "!unzip ngrok-stable-linux-amd64.zip &> /dev/null\n",
        "get_ipython().system_raw('./ngrok http 4050 &')"
      ],
      "metadata": {
        "id": "Xc_p5WZo0Kni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating PySpark DataFrames**\n",
        "\n",
        "There are a few ways to manually create PySpark DataFrames:\n",
        "\n",
        "createDataFrame\n",
        "\n",
        "create_df\n",
        "\n",
        "toDF\n",
        "\n",
        "\n",
        "\n",
        "**createDataFrame**\n",
        "Here’s how to create a DataFrame with createDataFrame:"
      ],
      "metadata": {
        "id": "untpqZNyHDky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([(\"joe\", 34), (\"luisa\", 22)], [\"first_name\", \"age\"])\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sYaQXvHHisA",
        "outputId": "13ecb8c5-3efa-4f29-f0a3-1d77e5b7ed02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---+\n",
            "|first_name|age|\n",
            "+----------+---+\n",
            "|       joe| 34|\n",
            "|     luisa| 22|\n",
            "+----------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBTkD2k9HsIg",
        "outputId": "16ce1a82-c035-42f4-b940-e2881ad481d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "df2 = spark.createDataFrame(data=data, schema = columns)"
      ],
      "metadata": {
        "id": "W0JgYWn3RSa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05tC-3l2RXfp",
        "outputId": "b2fa61be-da1e-44aa-8ed7-acba1ec6ea49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " dataDF = [(('James','','Smith'),'1991-04-01','M',3000),\n",
        "  (('Michael','Rose',''),'2000-05-19','M',4000),\n",
        "  (('Robert','','Williams'),'1978-09-05','M',4000),\n",
        "  (('Maria','Anne','Jones'),'1967-12-01','F',4000),\n",
        "  (('Jen','Mary','Brown'),'1980-02-17','F',-1)\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "a7ShGMSXRj1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our base schema with nested structure."
      ],
      "metadata": {
        "id": "ZO-tiZOWSJ5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n",
        "schema = StructType([\n",
        "        StructField('name', StructType([\n",
        "             StructField('firstname', StringType(), True),\n",
        "             StructField('middlename', StringType(), True),\n",
        "             StructField('lastname', StringType(), True)\n",
        "             ])),\n",
        "         StructField('dob', StringType(), True),\n",
        "         StructField('gender', StringType(), True),\n",
        "         StructField('gender', IntegerType(), True)\n",
        "         ])"
      ],
      "metadata": {
        "id": "tJkEKQ1MSJMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " df3 = spark.createDataFrame(data = dataDF, schema = schema)\n",
        " df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB7QNA9nSOm7",
        "outputId": "64a7ad06-7f43-40b8-ca25-5fd8badcd026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- gender: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PySpark withColumnRenamed\n",
        "\n",
        "– **To rename DataFrame column name**\n",
        "PySpark has a withColumnRenamed() function on DataFrame to change a column name. This is the most straight forward approach; this function takes two parameters; the first is your existing column name and the second is the new column name you wish for."
      ],
      "metadata": {
        "id": "zVhTCljaS479"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.withColumnRenamed(\"dob\",\"DateOfBirth\").printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQkIZ0ffTAPH",
        "outputId": "84c5097a-903e-468e-b1b1-efbb280e09a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- DateOfBirth: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- gender: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PySpark withColumnRenamed - To rename multiple columns**\n",
        "\n"
      ],
      "metadata": {
        "id": "xFLW6HfqTJiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.withColumnRenamed(\"dob\",\"DateOfBirth\") \\\n",
        "    .withColumnRenamed(\"salary\",\"salary_amount\")\n",
        "df3.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByDXbZ1WTSz6",
        "outputId": "3bb0ade9-ce4c-4e11-af4e-2acbc91209ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- DateOfBirth: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- gender: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema2 = StructType([\n",
        "    StructField(\"fname\",StringType()),\n",
        "    StructField(\"middlename\",StringType()),\n",
        "    StructField(\"lname\",StringType())])\n",
        "\n"
      ],
      "metadata": {
        "id": "830qCuagTyoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also pass createDataFrame a RDD and schema to construct DataFrames with more precision:"
      ],
      "metadata": {
        "id": "1uhYqnOdH33w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "rdd = spark.sparkContext.parallelize([\n",
        "    Row(name='Allie', age=2),\n",
        "    Row(name='Sara', age=33),\n",
        "    Row(name='Grace', age=31)])\n",
        "\n",
        "schema = schema = StructType([\n",
        "   StructField(\"name\", StringType(), True),\n",
        "   StructField(\"age\", IntegerType(), False)])\n",
        "\n",
        "df = spark.createDataFrame(rdd, schema)\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTa5Y2IeH25d",
        "outputId": "87b83f08-185b-41f3-ca64-739a9e4b8ba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Allie|  2|\n",
            "| Sara| 33|\n",
            "|Grace| 31|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create_df**\n",
        "\n",
        "The create_df method defined in quinn allows for precise schema definition when creating DataFrames."
      ],
      "metadata": {
        "id": "oj2VzzwFINaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install quinn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4daYfYcIvkk",
        "outputId": "c1ce3e5e-b60d-46d3-863e-a321bf6422d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting quinn\n",
            "  Downloading quinn-0.10.0-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: quinn\n",
            "Successfully installed quinn-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "from quinn.extensions import *\n",
        "\n",
        "df = spark.create_df(\n",
        "    [(\"jose\", \"a\"), (\"li\", \"b\"), (\"sam\", \"c\")],\n",
        "    [(\"name\", StringType(), True), (\"blah\", StringType(), True)]\n",
        ")\n",
        "\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFo9pNJbIVzY",
        "outputId": "24768372-d10e-4cc1-bed0-c8142d28a7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+\n",
            "|name|blah|\n",
            "+----+----+\n",
            "|jose|   a|\n",
            "|  li|   b|\n",
            "| sam|   c|\n",
            "+----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**italicised text**\n",
        "\n",
        "**toDF**  \n",
        "\n",
        "You can also create a RDD and convert it to a DataFrame with toDF:"
      ],
      "metadata": {
        "id": "ud9cp4YRJOsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "rdd = spark.sparkContext.parallelize([\n",
        "    Row(name='Allie', age=2),\n",
        "    Row(name='Sara', age=33),\n",
        "    Row(name='Grace', age=31)])\n",
        "df = rdd.toDF()\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pBSXHB9JNqi",
        "outputId": "57da5247-5175-4291-a9a1-4e567131bfe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| name|age|\n",
            "+-----+---+\n",
            "|Allie|  2|\n",
            "| Sara| 33|\n",
            "|Grace| 31|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a DataFrame\n",
        "To create our dataframe, we can start with a list of dictionaries in Python."
      ],
      "metadata": {
        "id": "VxgKThXC-je7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NwQjCkNiIUID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies = [{'index': 1,\n",
        "  'title': 'Shazam!',\n",
        "  'release_date': 1553299200,\n",
        "  'genre': 'Comedy'}, {'index': 2,\n",
        "  'title': 'Captain Marvel',\n",
        "  'release_date': 1551830400,\n",
        "  'genre': 'Action'},  {'index': 3,\n",
        "  'title': 'Escape Room',\n",
        "  'release_date': 1546473600,\n",
        "  'genre': 'Horror'}, {'index': 4,\n",
        "  'title': 'How to Train A Dragon',\n",
        "  'release_date': 1546473600,\n",
        "  'genre': 'Animation'}]"
      ],
      "metadata": {
        "id": "baNMZE-J-t_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So here we have a list of movies displaying the title, release_date and genre of each movie.\n",
        "\n",
        "And then we can use the createDataFrame method on the spark session to create our dataframe."
      ],
      "metadata": {
        "id": "F1dCANy_-ns1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = spark.createDataFrame(movies)\n",
        "movies_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9l_jIce-PRy",
        "outputId": "edff67ba-c77a-4760-c8d9-c6e2542fee95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+------------+--------------------+\n",
            "|    genre|index|release_date|               title|\n",
            "+---------+-----+------------+--------------------+\n",
            "|   Comedy|    1|  1553299200|             Shazam!|\n",
            "|   Action|    2|  1551830400|      Captain Marvel|\n",
            "|   Horror|    3|  1546473600|         Escape Room|\n",
            "|Animation|    4|  1546473600|How to Train A Dr...|\n",
            "+---------+-----+------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can see from the above, that our dataframe organizes our data in a table. It has associated our records with various columns.\n",
        "\n",
        "We can also see the schema on read characteristic from spark. That even without specifying a datatype, Spark was able to determine the datatype for each column."
      ],
      "metadata": {
        "id": "xl5x6qIg_b5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAVG18Pc_awf",
        "outputId": "c7d96f24-26de-4bd2-f9a9-cbedb72a2b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- genre: string (nullable = true)\n",
            " |-- index: long (nullable = true)\n",
            " |-- release_date: long (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From DataFrame to RDD\n",
        "\n",
        "Now a dataframe in Pyspark creates an RDD under the hood."
      ],
      "metadata": {
        "id": "qc5iizMt_qWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.rdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P3PnJBj_j1F",
        "outputId": "c46cb0c4-477c-4760-9c25-5d81a50513a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MapPartitionsRDD[74] at javaToPython at NativeMethodAccessorImpl.java:0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idJ5MDci_0mo",
        "outputId": "175ef31f-283c-4322-b2e8-2d51d04fabf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(genre='Comedy', index=1, release_date=1553299200, title='Shazam!'),\n",
              " Row(genre='Action', index=2, release_date=1551830400, title='Captain Marvel'),\n",
              " Row(genre='Horror', index=3, release_date=1546473600, title='Escape Room'),\n",
              " Row(genre='Animation', index=4, release_date=1546473600, title='How to Train A Dragon')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **It's distributed**\n",
        "And that even though this looks like a unified dataset, it's really distributed across different nodes."
      ],
      "metadata": {
        "id": "YalGNFjJ_7r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFnSGH_E_3V1",
        "outputId": "ac1672d8-2fef-47fd-edd1-c8cea2104cc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It's lazy**\n",
        "\n",
        "Because our dataset is built on RDDs, is also operates in lazy manner. So for example, if we want to select all of the titles of an RDD, we'll use a map function to select the title from each row. But because map is a transformation, it will not operate on our data, until we follow up with an action."
      ],
      "metadata": {
        "id": "Q9IdS9W_EBRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.rdd.map(lambda movie: movie['title'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXhk1PaQD9kv",
        "outputId": "a4b28d01-469f-459e-a1da-81bd2dc40b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[75] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.rdd.map(lambda movie: movie['title']).collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DjTEw5JEKej",
        "outputId": "78669355-fdf2-452d-c197-d4c39e73f1eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Shazam!', 'Captain Marvel', 'Escape Room', 'How to Train A Dragon']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we perform the equivalent operation with a dataframe, the operation is also treated as a transformation. Let's see this. Below, we'll select the title of each record."
      ],
      "metadata": {
        "id": "WxJ2TStaESax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.select('title')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiLF54SbEPpB",
        "outputId": "c9994afd-5ec0-402a-9cf4-fbaacd8f2565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[title: string]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So again, spark will not search through each of the records until an action is called."
      ],
      "metadata": {
        "id": "SnB-scSYEees"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.select('title').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfRO0Jy3EdcT",
        "outputId": "aeb0bb97-b361-4803-d86d-b52a7460c973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               title|\n",
            "+--------------------+\n",
            "|             Shazam!|\n",
            "|      Captain Marvel|\n",
            "|         Escape Room|\n",
            "|How to Train A Dr...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.select(['title', 'genre']).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAd8T8LfFPoM",
        "outputId": "322cd35a-33ee-459b-952f-eaea3a7cf2e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|               title|    genre|\n",
            "+--------------------+---------+\n",
            "|             Shazam!|   Comedy|\n",
            "|      Captain Marvel|   Action|\n",
            "|         Escape Room|   Horror|\n",
            "|How to Train A Dr...|Animation|\n",
            "+--------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4N52ctbDG6o5"
      }
    }
  ]
}